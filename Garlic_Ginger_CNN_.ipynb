{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajmainrahman/ML-Projects/blob/main/Garlic_Ginger_CNN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_BQc2PRMkAP",
        "outputId": "3d42cf75-e7a5-4775-f111-cabfd11be85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 503 images belonging to 2 classes.\n",
            "Found 117 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create a new generator\n",
        "imagegen = ImageDataGenerator()\n",
        "# load train data\n",
        "train = imagegen.flow_from_directory(\"/content/drive/MyDrive/Dataset/GarlicGingerDataset/Train\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
        "# load val data\n",
        "val = imagegen.flow_from_directory(\"/content/drive/MyDrive/Dataset/GarlicGingerDataset/Test\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHxgTpXBQHCk",
        "outputId": "284b2674-4d01-49c4-b2e7-b4ac67335a84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 436s 121s/step - loss: 2.3113 - accuracy: 0.6183 - val_loss: 16.7888 - val_accuracy: 0.3590\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 329s 82s/step - loss: 0.3789 - accuracy: 0.8350 - val_loss: 19.6483 - val_accuracy: 0.6410\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 328s 86s/step - loss: 0.2408 - accuracy: 0.9006 - val_loss: 44.7711 - val_accuracy: 0.6410\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 323s 84s/step - loss: 0.1471 - accuracy: 0.9344 - val_loss: 53.6980 - val_accuracy: 0.6410\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 329s 82s/step - loss: 0.1255 - accuracy: 0.9344 - val_loss: 54.2004 - val_accuracy: 0.6410\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 330s 84s/step - loss: 0.0854 - accuracy: 0.9722 - val_loss: 51.6195 - val_accuracy: 0.6410\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 319s 82s/step - loss: 0.1162 - accuracy: 0.9404 - val_loss: 48.8529 - val_accuracy: 0.6410\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 330s 87s/step - loss: 0.0674 - accuracy: 0.9761 - val_loss: 41.2382 - val_accuracy: 0.6410\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 319s 82s/step - loss: 0.0773 - accuracy: 0.9781 - val_loss: 37.1844 - val_accuracy: 0.6410\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 329s 87s/step - loss: 0.1234 - accuracy: 0.9523 - val_loss: 36.0924 - val_accuracy: 0.6410\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4539d5b950>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout\n",
        "\n",
        "# build a sequential model\n",
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
        "\n",
        "# 1st conv block\n",
        "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "# 2nd conv block\n",
        "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "# 3rd conv block\n",
        "model.add(Conv2D(125, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "# ANN block\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "# output layer\n",
        "model.add(Dense(units=2, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "# fit on data for 10 epochs\n",
        "model.fit(train, epochs=10, validation_data=val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLNExM2K3oJM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1iROWz41yNvaFO6c11Px62wSgJzp4rkpa",
      "authorship_tag": "ABX9TyPEU7FBgn/q2dG7Cfv88rUW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}