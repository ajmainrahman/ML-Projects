{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajmainrahman/ML-Projects/blob/main/image_classification_w_vgg19_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "da4cce1590dc1cac991d7562522ac8f16f6c5f48",
        "id": "8gBWv0_QgJYJ"
      },
      "source": [
        "In this notebook, we are going to use pretrained weights of VGG 19 and then add a new output layer with the required number of classes. In order to use the pretrained weights, you need add a new dataset containing the weights. Go to Data tab and click on 'Add Data Source'. Then search for 'Keras Pretrained Model' dataset which contains weights of different architectures like VGG19, Inception, Resnet50, Xception.\n",
        "\n",
        "The dataset contains 3 directories: Training, Validation and Testing. Each directory contains sub-directories with images of different fruits."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lit2kLbqgQug",
        "outputId": "d5b27552-d5ca-4ec3-a6b2-22839a4f947e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "0bTHE3OAgJYN"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "593f6bf3064a52388f6f6dd2df6252980a631e6f",
        "id": "jxCKIFkigJYP"
      },
      "outputs": [],
      "source": [
        "# loading the directories \n",
        "training_dir = '../input/fruits/fruits-360_dataset/fruits-360/Training/'\n",
        "validation_dir = '../input/fruits/fruits-360_dataset/fruits-360/Test/'\n",
        "test_dir = '../input/fruits/fruits-360_dataset/fruits-360/test-multiple_fruits/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "2687d1c9f4a5d3aa631dfac1cd3c26fd0dd3d166",
        "id": "HJJ3wXKhgJYP"
      },
      "outputs": [],
      "source": [
        "# useful for getting number of files\n",
        "image_files = glob(training_dir + '/*/*.jp*g')\n",
        "valid_image_files = glob(validation_dir + '/*/*.jp*g')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "d9ecb46c4d6c9d2cf744b36cfced6398752383a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cak2zkgZgJYQ",
        "outputId": "2975af86-c692-403b-feed-011fd99c591b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Classes = 0\n"
          ]
        }
      ],
      "source": [
        "# getting the number of classes i.e. type of fruits\n",
        "folders = glob(training_dir + '/*')\n",
        "num_classes = len(folders)\n",
        "print ('Total Classes = ' + str(num_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "45d613325b9c0f27d67c44590aa191d67a91050f",
        "id": "81KfYMaVgJYR"
      },
      "outputs": [],
      "source": [
        "# this will copy the pretrained weights to our kernel\n",
        "!mkdir ~/.keras\n",
        "!mkdir ~/.keras/models\n",
        "!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n",
        "!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "cfdd83abd9a203157499159e0e087c9530aeea1a",
        "id": "N6i8U9BsgJYS"
      },
      "outputs": [],
      "source": [
        "# importing the libraries\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.applications import VGG19\n",
        "#from keras.preprocessing import image\n",
        "\n",
        "IMAGE_SIZE = [64, 64]  # we will keep the image size as (64,64). You can increase the size for better results. \n",
        "\n",
        "# loading the weights of VGG19 without the top layer. These weights are trained on Imagenet dataset.\n",
        "vgg = VGG19(input_shape = IMAGE_SIZE + [3], weights = 'imagenet', include_top = False)  # input_shape = (64,64,3) as required by VGG\n",
        "\n",
        "# this will exclude the initial layers from training phase as there are already been trained.\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(vgg.output)\n",
        "#x = Dense(128, activation = 'relu')(x)   # we can add a new fully connected layer but it will increase the execution time.\n",
        "x = Dense(num_classes, activation = 'softmax')(x)  # adding the output layer with softmax function as this is a multi label classification problem.\n",
        "\n",
        "model = Model(inputs = vgg.input, outputs = x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "703eb0b5beabb2508c5381b7f21d048f64712e8f",
        "id": "HJqpeCVKgJYT"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "24bccf942ce0f39558cff2a04a18a6a30ede9998",
        "scrolled": false,
        "id": "-te9srjXgJYU",
        "outputId": "dbe51f9a-3946-459b-a24a-ea28192213fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 48905 images belonging to 95 classes.\n",
            "Found 16421 images belonging to 95 classes.\n"
          ]
        }
      ],
      "source": [
        "# Image Augmentation\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "\n",
        "training_datagen = ImageDataGenerator(\n",
        "                                    rescale=1./255,   # all pixel values will be between 0 an 1\n",
        "                                    shear_range=0.2, \n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    preprocessing_function=preprocess_input)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255, preprocessing_function=preprocess_input)\n",
        "\n",
        "training_generator = training_datagen.flow_from_directory(training_dir, target_size = IMAGE_SIZE, batch_size = 200, class_mode = 'categorical')\n",
        "validation_generator = validation_datagen.flow_from_directory(validation_dir, target_size = IMAGE_SIZE, batch_size = 200, class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "571943a0ecb771740ceba5fe198f936a8e311fb0",
        "id": "dF_GGFgjgJYV"
      },
      "source": [
        "We have not used any X_train, y_train, X_test, y_test or generated any labels for our classes. It is because we are using the flow_from_directory function of ImageDataGenerator. This function takes a directory as an input and assign the class indices to its sub directories. For this function to work, each subdirectory must contain a single class object only.\n",
        "Another function of ImageDataGenerator is 'flow'. With this function, we need to provide X_train, y_train. If you use X_train, y_train, X_test, y_test, don't forget to normalize X_train and X_test and use on hot encoding for y_train and y_test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "96302bd261bd293fe19b02ae88f2ab5ddaa75d07",
        "id": "4ayN7cM2gJYV"
      },
      "outputs": [],
      "source": [
        "# The labels are stored in class_indices in dictionary form. \n",
        "# checking the labels\n",
        "training_generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": false,
        "_uuid": "ffb1b7ce1f7560753f83a10de47cf290fbec9159",
        "scrolled": true,
        "id": "nZknuhw7gJYW"
      },
      "outputs": [],
      "source": [
        "training_images = 37836\n",
        "validation_images = 12709\n",
        "\n",
        "history = model.fit_generator(training_generator,\n",
        "                   steps_per_epoch = 10,  # this should be equal to total number of images in training set. But to speed up the execution, I am only using 10000 images. Change this for better results. \n",
        "                   epochs = 1,  # change this for better results\n",
        "                   validation_data = validation_generator,\n",
        "                   validation_steps = 10)  # this should be equal to total number of images in validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_uuid": "c147c541d4c6d71d03cf2011c6933486b05db1da",
        "id": "NASoKW64gJYW"
      },
      "outputs": [],
      "source": [
        "print ('Training Accuracy = ' + str(history.history['acc']))\n",
        "print ('Validation Accuracy = ' + str(history.history['val_acc']))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}