{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajmainrahman/ML-Projects/blob/main/Ginger_and_Garlic_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2deBIMtyAHx"
      },
      "source": [
        "# Imorts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5KXeMMVyAHy"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from functools import partial\n",
        "from collections import namedtuple\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB7\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.applications import ResNet101\n",
        "from tensorflow.keras.applications import ResNet101V2\n",
        "from tensorflow.keras.applications import ResNet152\n",
        "\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Activation, Dropout, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn06uH9-yAH0"
      },
      "source": [
        "# Prepare the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5wygNjAyAH2"
      },
      "outputs": [],
      "source": [
        "#INPUT_ROOT = '/content/drive/MyDrive/lung and colon cancer/lung_colon_image_set'\n",
        "#DATA_DIR = os.path.join(INPUT_ROOT, '/content/drive/MyDrive/lung and colon cancer/lung_colon_image_set/colon_image_sets', '/content/drive/MyDrive/lung and colon cancer/lung_colon_image_set/lung_image_sets')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNsYyFFUboRv"
      },
      "outputs": [],
      "source": [
        "INPUT_ROOT = '/content/drive/MyDrive/Dataset/GarlicGingerDataset/Train'\n",
        "DATA_DIR = os.path.join(INPUT_ROOT, '/content/drive/MyDrive/Research Paper - 22/Research with Asad Sir/Dataset/Lung_and_Colon_Cancer/Colon_Cancer','/content/drive/MyDrive/Research Paper - 22/Research with Asad Sir/Dataset/Lung_and_Colon_Cancer/Lung_Cancer')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/MyDrive/Dataset/GarlicGingerDataset/Train\"   #Setting training directory\n",
        "validation_dir = \"/content/drive/MyDrive/Dataset/GarlicGingerDataset/Test\"   #Setting testing directory\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator "
      ],
      "metadata": {
        "id": "00cifAvuOl41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrjVMCX2yAH7"
      },
      "source": [
        "# Generate the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmSuATQKyAH7"
      },
      "outputs": [],
      "source": [
        "data = image.ImageDataGenerator(validation_split = 0.2)\n",
        "BATCH_SIZE = 128\n",
        "# Change batch size, if you run out of memory!\n",
        "# Or increase it, if you have a lot of RAM (>> 16 Gb) for faster trainig\n",
        "IMG_SHAPE = (256, 256, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "GZ20-ShJyAH8",
        "outputId": "e211b026-5b84-447a-ba81-2285bfb37ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainig data:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e9220efdfee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Trainig data:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validating data:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mvalidate_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m       \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m           \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Dataset/GarlicGingerDataset/Test'"
          ]
        }
      ],
      "source": [
        "generate_data = partial(\n",
        "    data.flow_from_directory,\n",
        "    validation_dir,\n",
        "    class_mode = 'categorical',\n",
        "    color_mode = 'rgb',\n",
        "    target_size = IMG_SHAPE[:2],\n",
        "    batch_size = BATCH_SIZE,\n",
        "    shuffle = False,\n",
        "    seed = 666\n",
        ")\n",
        "\n",
        "print('Trainig data:')\n",
        "train_iter = generate_data(subset='training')\n",
        "print('Validating data:')\n",
        "validate_iter = generate_data(subset='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW3AwU2UyAH9",
        "outputId": "08e9b46c-0386-48aa-cf00-9b68687fac76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "functools.partial(<bound method ImageDataGenerator.flow_from_directory of <keras.preprocessing.image.ImageDataGenerator object at 0x7f6340ef7510>>, '/content/drive/MyDrive/Research Paper - 22/Research with Asad Sir/Dataset/Lung_and_Colon_Cancer/Lung_Cancer', class_mode='categorical', color_mode='rgb', target_size=(256, 256), batch_size=128, shuffle=False, seed=666)\n"
          ]
        }
      ],
      "source": [
        "print(generate_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyYRiekSyAH-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbUQqUeOyAH-",
        "outputId": "3c2725f9-deb2-4322-8171-30f0f5914da8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(256, 256)\n"
          ]
        }
      ],
      "source": [
        "print(IMG_SHAPE[:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgUJ76PCyAH_",
        "outputId": "06ea61f6-575a-4426-cf2f-90df40a64e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 256, 256, 3)\n",
            "(128, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "l = list(train_iter[0])\n",
        "print(l[0].shape)\n",
        "print(l[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ItcGvtUyAH_",
        "outputId": "32dc4f2f-8de8-419e-b693-ca016591116d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "128\n"
          ]
        }
      ],
      "source": [
        "print(len(l[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5yn7xlRyAH_",
        "outputId": "a0dc8a99-c00b-401d-e269-e6b2a2305d01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "for i in range(15):\n",
        "    print(l[0][i])\n",
        "    print(\"\\n\")\n",
        "'''    \n",
        "arr = l[0][1]\n",
        "print(type(arr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n7xSuYvyAIA"
      },
      "outputs": [],
      "source": [
        "from PIL import Image as im\n",
        "data = im.fromarray(arr,'RGB')\n",
        "data.save('gfg_dummy_pic.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEoEfLcgyAIA"
      },
      "outputs": [],
      "source": [
        "CLASSES_NUM = 3\n",
        "ACCURACY_THRESHOLD = 0.99\n",
        "\n",
        "# Set to True to train simple from scratch CNN\n",
        "RUN_SIMPLE_CNN = False\n",
        "\n",
        "# Set to True to use fine-tuning\n",
        "RUN_PRETRAINED = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HECbNLJ8yAIB"
      },
      "source": [
        "# Fine-tuned models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pRgda2zyAIB"
      },
      "source": [
        "Some constants that are used for this particular dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-fxsz8dyAIB"
      },
      "source": [
        "### Preparing pretrained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqgkO9OHyAIC"
      },
      "outputs": [],
      "source": [
        "PreparedModel = namedtuple('PreparedModel', ['name', 'keras_pretrained', 'optimizer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXiosdrYyAIC"
      },
      "outputs": [],
      "source": [
        "def get_keras_pretrained(keras_model):\n",
        "    pretrained = keras_model(\n",
        "        input_shape=IMG_SHAPE,\n",
        "        weights='imagenet',\n",
        "        include_top=False\n",
        "    )\n",
        "    pretrained.trainable = False\n",
        "    return pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUPzB5u1yAID"
      },
      "outputs": [],
      "source": [
        "if RUN_PRETRAINED:\n",
        "    prepared_VGG16 = PreparedModel('VGG16', get_keras_pretrained(VGG16), 'adam')\n",
        "    prepared_EfficientNetB7 = PreparedModel('EfficientNetB7', get_keras_pretrained(EfficientNetB7), 'adam')\n",
        "    prepared_InceptionV3 = PreparedModel('InceptionV3', get_keras_pretrained(InceptionV3), SGD(learning_rate=0.001, momentum=0.9))\n",
        "    prepared_ResNet50 = PreparedModel('ResNet50', get_keras_pretrained(ResNet50), 'adam')\n",
        "  \n",
        "    prepared_VGG19 = PreparedModel('VGG19', get_keras_pretrained(VGG19), 'adam')\n",
        "    prepared_ResNet50V2 = PreparedModel('ResNet50V2', get_keras_pretrained(ResNet50V2), 'adam')\n",
        "  \n",
        "    \n",
        "    #prepared_InceptionResNetV2 = PreparedModel('InceptionResNetV2', get_keras_pretrained(InceptionResNetV2), SGD(learning_rate=0.001, momentum=0.9))\n",
        "    #prepared_MobileNet = PreparedModel('MobileNet', get_keras_pretrained(MobileNet), 'adam')\n",
        "    #prepared_MobileNetV2 = PreparedModel('MobileNetV2', get_keras_pretrained(MobileNetV2), 'adam')  \n",
        "    \n",
        "\n",
        "    # If you have no time limit, you can include all the models and run it\n",
        "    # But if you use kaggle, it's better to include just one and run multiple times\n",
        "    # You can also use the callback below or EarlyStopping\n",
        "    #models = [prepared_ResNet101, prepared_ResNet101V2, prepared_ResNet152, prepared_ResNet152V2, prepared_InceptionResNetV2, prepared_MobileNet, prepared_MobileNetV2, prepared_DenseNet121, prepared_DenseNet169, prepared_DenseNet201]\n",
        "    models = [prepared_EfficientNetB7]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9GGng-ZyAID"
      },
      "outputs": [],
      "source": [
        "class TresholdStopping(tf.keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, point):\n",
        "        super(TresholdStopping, self).__init__()\n",
        "        self.point = point\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None): \n",
        "        accuracy = logs['val_accuracy']\n",
        "        if accuracy >= self.point:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "treshold_stopping = TresholdStopping(ACCURACY_THRESHOLD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6RUuv46yAIE"
      },
      "source": [
        "### Fit using our top layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z7W1A0VyAIE"
      },
      "outputs": [],
      "source": [
        "def top_layer(output):\n",
        "    layer = GlobalAveragePooling2D()(output)\n",
        "    layer = Flatten()(layer)\n",
        "    layer = Dense(128, activation='relu')(layer)\n",
        "    # layer = Dropout(0.5)(layer)\n",
        "    # Drop out layer is optional: you may include it to fix overfitting\n",
        "    layer = Dense(64, activation='relu')(layer)\n",
        "    layer = Dense(CLASSES_NUM, activation='softmax')(layer)\n",
        "    return layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-vhIiHcyAIF"
      },
      "source": [
        "Fit the models, saving weigths and logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vISmRCvfyAIF",
        "outputId": "ba76a7e2-7f8f-454c-bf3d-dbb65eb5ffb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STARTED TRAINIG OF EfficientNetB7 PREPARED MODEL\n",
            "Epoch 1/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.7956 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.94270, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 2366s 25s/step - loss: 0.4682 - accuracy: 0.7956 - val_loss: 0.1619 - val_accuracy: 0.9427\n",
            "Epoch 2/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.1624 - accuracy: 0.9380\n",
            "Epoch 2: val_accuracy did not improve from 0.94270\n",
            "94/94 [==============================] - 209s 2s/step - loss: 0.1624 - accuracy: 0.9380 - val_loss: 0.1847 - val_accuracy: 0.9234\n",
            "Epoch 3/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9478\n",
            "Epoch 3: val_accuracy improved from 0.94270 to 0.95536, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 210s 2s/step - loss: 0.1344 - accuracy: 0.9478 - val_loss: 0.1136 - val_accuracy: 0.9554\n",
            "Epoch 4/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.9548\n",
            "Epoch 4: val_accuracy improved from 0.95536 to 0.96935, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 210s 2s/step - loss: 0.1181 - accuracy: 0.9548 - val_loss: 0.0816 - val_accuracy: 0.9694\n",
            "Epoch 5/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9677\n",
            "Epoch 5: val_accuracy improved from 0.96935 to 0.96969, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 210s 2s/step - loss: 0.0853 - accuracy: 0.9677 - val_loss: 0.0767 - val_accuracy: 0.9697\n",
            "Epoch 6/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9679\n",
            "Epoch 6: val_accuracy improved from 0.96969 to 0.97602, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 210s 2s/step - loss: 0.0836 - accuracy: 0.9679 - val_loss: 0.0623 - val_accuracy: 0.9760\n",
            "Epoch 7/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9738\n",
            "Epoch 7: val_accuracy improved from 0.97602 to 0.97768, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 210s 2s/step - loss: 0.0695 - accuracy: 0.9738 - val_loss: 0.0523 - val_accuracy: 0.9777\n",
            "Epoch 8/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9768\n",
            "Epoch 8: val_accuracy improved from 0.97768 to 0.97801, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 210s 2s/step - loss: 0.0594 - accuracy: 0.9768 - val_loss: 0.0552 - val_accuracy: 0.9780\n",
            "Epoch 9/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9784\n",
            "Epoch 9: val_accuracy improved from 0.97801 to 0.98235, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 210s 2s/step - loss: 0.0581 - accuracy: 0.9784 - val_loss: 0.0454 - val_accuracy: 0.9823\n",
            "Epoch 10/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.9805\n",
            "Epoch 10: val_accuracy improved from 0.98235 to 0.98568, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 209s 2s/step - loss: 0.0533 - accuracy: 0.9805 - val_loss: 0.0375 - val_accuracy: 0.9857\n",
            "Epoch 11/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9855\n",
            "Epoch 11: val_accuracy did not improve from 0.98568\n",
            "94/94 [==============================] - 208s 2s/step - loss: 0.0418 - accuracy: 0.9855 - val_loss: 0.0440 - val_accuracy: 0.9827\n",
            "Epoch 12/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9867\n",
            "Epoch 12: val_accuracy improved from 0.98568 to 0.98901, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 209s 2s/step - loss: 0.0371 - accuracy: 0.9867 - val_loss: 0.0303 - val_accuracy: 0.9890\n",
            "Epoch 13/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9872\n",
            "Epoch 13: val_accuracy did not improve from 0.98901\n",
            "94/94 [==============================] - 209s 2s/step - loss: 0.0348 - accuracy: 0.9872 - val_loss: 0.0309 - val_accuracy: 0.9880\n",
            "Epoch 14/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9913\n",
            "Epoch 14: val_accuracy improved from 0.98901 to 0.99201, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 209s 2s/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0197 - val_accuracy: 0.9920\n",
            "Epoch 15/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9921\n",
            "Epoch 15: val_accuracy improved from 0.99201 to 0.99300, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 210s 2s/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.0192 - val_accuracy: 0.9930\n",
            "Epoch 16/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 0.9928\n",
            "Epoch 16: val_accuracy did not improve from 0.99300\n",
            "94/94 [==============================] - 208s 2s/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.0242 - val_accuracy: 0.9920\n",
            "Epoch 17/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9590\n",
            "Epoch 17: val_accuracy did not improve from 0.99300\n",
            "94/94 [==============================] - 208s 2s/step - loss: 0.1199 - accuracy: 0.9590 - val_loss: 0.0886 - val_accuracy: 0.9680\n",
            "Epoch 18/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9781\n",
            "Epoch 18: val_accuracy did not improve from 0.99300\n",
            "94/94 [==============================] - 209s 2s/step - loss: 0.0572 - accuracy: 0.9781 - val_loss: 0.0376 - val_accuracy: 0.9830\n",
            "Epoch 19/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9902\n",
            "Epoch 19: val_accuracy did not improve from 0.99300\n",
            "94/94 [==============================] - 208s 2s/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.0229 - val_accuracy: 0.9910\n",
            "Epoch 20/20\n",
            "94/94 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9913\n",
            "Epoch 20: val_accuracy improved from 0.99300 to 0.99434, saving model to EfficientNetB7\n",
            "94/94 [==============================] - 209s 2s/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.0179 - val_accuracy: 0.9943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 273). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAINIG OF EfficientNetB7 COMPLETED\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "if RUN_PRETRAINED:    \n",
        "    for prepared_model in models:\n",
        "\n",
        "        keras_pretrained = prepared_model.keras_pretrained\n",
        "\n",
        "        model = Model(inputs=keras_pretrained.input, outputs=top_layer(keras_pretrained.output))\n",
        "\n",
        "        model.compile(\n",
        "          loss='categorical_crossentropy',\n",
        "          optimizer=prepared_model.optimizer,\n",
        "          metrics=['accuracy'],\n",
        "\n",
        "        )\n",
        "\n",
        "        checkpointing = ModelCheckpoint(\n",
        "            filepath=prepared_model.name,\n",
        "            save_weights_only=True,\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy',\n",
        "            mode='max',\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        log_saving = CSVLogger(f'{prepared_model.name}-log.csv', append=True, separator=';')\n",
        "\n",
        "        print(f'STARTED TRAINIG OF {prepared_model.name} PREPARED MODEL')\n",
        "\n",
        "        model.fit(\n",
        "            train_iter,\n",
        "            validation_data=validate_iter,\n",
        "            epochs=20,\n",
        "            callbacks=[checkpointing, log_saving]\n",
        "        )\n",
        "        \n",
        "        # save model\n",
        "        filename = 'finalized_model.sav'\n",
        "        pickle.dump(model, open(filename, 'wb'))\n",
        "        \n",
        "        model.save('finalized_model.h5')\n",
        "        \n",
        "        print(f'TRAINIG OF {prepared_model.name} COMPLETED')\n",
        "        print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbP8n4LYyAIG"
      },
      "outputs": [],
      "source": [
        "filename = 'finalized_model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        "#model.save('finalized_model.h5')\n",
        "#model.save_weights('my_model_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RvzDbc6GyAIG",
        "outputId": "7e37a4b0-5300-4bbc-e0f1-5de6861a4e89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.preprocessing.image.DirectoryIterator object at 0x7f6341085790>\n"
          ]
        }
      ],
      "source": [
        "print(train_iter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaF4SAnZyAIH"
      },
      "source": [
        "# Model from scratch\n",
        "\n",
        "To compare with fine-tuning approach, we will also train simple CNN model without any typical architecture and weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX4U0dckyAIH"
      },
      "outputs": [],
      "source": [
        "# Features extraction layers\n",
        "simple_CNN_model = tf.keras.models.Sequential([\n",
        "    \n",
        "    Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=IMG_SHAPE),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(2),\n",
        "    \n",
        "    Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(2),\n",
        "  \n",
        "    Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(2)\n",
        "])\n",
        "\n",
        "# Classification layers\n",
        "simple_CNN_model.add(Flatten())\n",
        "simple_CNN_model.add(Dense(128, activation='relu'))\n",
        "simple_CNN_model.add(Dense(64, activation='relu'))\n",
        "simple_CNN_model.add(Dense(CLASSES_NUM, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nuxVS6byAIH"
      },
      "outputs": [],
      "source": [
        "simple_CNN_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_K2_XVnyAII"
      },
      "source": [
        "Callbacks for saving weigths and log:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_29Ofj9SyAII"
      },
      "outputs": [],
      "source": [
        "name = 'SimpleCNN'\n",
        "\n",
        "checkpointing = ModelCheckpoint(\n",
        "    name,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "log_saving = CSVLogger(f'{name}-log.csv', append=True, separator=';')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OC0lS69yAII"
      },
      "outputs": [],
      "source": [
        "if RUN_SIMPLE_CNN:\n",
        "    \n",
        "    print(f'{name} IS READY FOR TRAINIG:')\n",
        "    simple_CNN_model.summary()\n",
        "    \n",
        "    print(f'STARTED TRAINIG OF {name} FROM SCRATCH MODEL')\n",
        "\n",
        "    simple_CNN_model.fit(\n",
        "        train_iter,\n",
        "        validation_data=validate_iter,\n",
        "        epochs=1,\n",
        "        callbacks=[checkpointing, log_saving]\n",
        "    )\n",
        "\n",
        "    print(f'TRAINIG OF {name} COMPLETED')\n",
        "    print('------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZEIXrLkyAII"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.open('/content/drive/MyDrive/lung and colon cancer/lung_colon_image_set/lung_image_sets/lung_aca/lungaca1.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv-7yAtHyAIJ"
      },
      "outputs": [],
      "source": [
        "#eff = pickle.load(open('../input/finalized-model/finalized_model.sav', 'rb'))\n",
        "import h5py\n",
        "from keras import models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JoYMNqcyAIJ"
      },
      "outputs": [],
      "source": [
        "model = models.load_model('/content/finalized_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zv_hYTpkyAIJ"
      },
      "outputs": [],
      "source": [
        "X_test = Image.open('/content/drive/MyDrive/lung and colon cancer/lung_colon_image_set/lung_image_sets/lung_aca/lungaca1.jpeg')\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "#y_pred = model.predict(X_test)\n",
        "#print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T79rPGsyAIJ"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def load_image(img_path, show=False):\n",
        "\n",
        "   img = keras.utils.load_img(img_path, target_size=(256, 256,3))\n",
        "    #img = image.load_img(img_path, target_size=(256, 256,3))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    #img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "\n",
        "# load model\n",
        "#model = load_model(\"model_aug.h5\")\n",
        "\n",
        "\n",
        "img_path1 = img_path+'lung_aca/lungaca10.jpeg'\n",
        "img_path2 = img_path+'lung_n/lungn1000.jpeg'\n",
        "img_path3 = img_path+'lung_scc/lungscc1.jpeg'\n",
        "# load a single image\n",
        "new_image = load_image(img_path1)\n",
        "\n",
        "# check prediction\n",
        "pred = model.predict(new_image)\n",
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvmkDD_1yAIK"
      },
      "outputs": [],
      "source": [
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3LwEnihyAIK"
      },
      "outputs": [],
      "source": [
        "print(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_pFliQ65QTz"
      },
      "outputs": [],
      "source": [
        "# plotting the loss\n",
        "plt.plot(history.history['loss'],label = 'train_loss')\n",
        "plt.plot(history.history['val_loss'], label = 'testing_loss')\n",
        "plt.title('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D6UymDm5SwC"
      },
      "outputs": [],
      "source": [
        "# Both Validation and Training accuracy is shown here\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='training_accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixm_YtBP5WAa"
      },
      "outputs": [],
      "source": [
        "# CHECKING THE CONFUSION MATRIX\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "Y_pred = model.predict_generator(validate_set)\n",
        "y_pred = np.argmax(Y_pred ,axis =1)\n",
        "print('Confusion Matrix')\n",
        "confusion_matrix = confusion_matrix(validate_set.classes, y_pred)\n",
        "print(confusion_matrix)\n",
        "print('Classification Report')\n",
        "target_names = ['aca','n', 'scc']\n",
        "print(classification_report(validate_set.classes, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6olqk-rZhmrn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}